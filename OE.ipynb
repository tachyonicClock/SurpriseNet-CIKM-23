{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¡ \n",
    "If outlier exposure is used does a neural network perform better? The hypothesis is that it will learn a more general representation that won't be interfered with as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "import torch\n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np\n",
    "import torchvision.datasets\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from dataclasses import dataclass\n",
    "from avalanche.benchmarks.classic.cmnist import SplitMNIST\n",
    "from avalanche.training.templates.supervised import SupervisedTemplate\n",
    "from avalanche.benchmarks.utils import AvalancheSubset, AvalancheDataset\n",
    "from avalanche.benchmarks.scenarios.new_classes.nc_scenario import NCScenario\n",
    "from avalanche.training.plugins.lwf import LwFPlugin\n",
    "from avalanche.training.plugins.synaptic_intelligence import SynapticIntelligencePlugin\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from conf import *\n",
    "from experiment.experiment import Experiment, BaseHyperParameters\n",
    "from functional.functional import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean tensor([0.1307]), std tensor([0.3081]), n 60000\n"
     ]
    }
   ],
   "source": [
    "def get_mean_and_std(dataloader):\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in dataloader:\n",
    "        # Mean over batch, height and width, but not over the channels\n",
    "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum / num_batches\n",
    "\n",
    "    # std = sqrt(E[X^2] - (E[X])^2)\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "\n",
    "    # pass\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    DATASETS, \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64)\n",
    "mean, std = get_mean_and_std(loader)\n",
    "\n",
    "print(f\"mean {mean}, std {std}, n {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperParams(BaseHyperParameters):\n",
    "    exposure_set_size: int\n",
    "    weight_decay: float\n",
    "\n",
    "class OE_Experiment(Experiment):\n",
    "\n",
    "    hp: HyperParams\n",
    "    network: MySimpleMLP\n",
    "\n",
    "    classifier_weight: float = 50.0\n",
    "\n",
    "    def __init__(self, hp: HyperParams) -> None:\n",
    "        super().__init__(hp)\n",
    "        self.classes_seen: typing.Set[int] = set()\n",
    "        self.after_eval_forward = self.after_forward\n",
    "\n",
    "    def make_network(self) -> nn.Module:\n",
    "        return MySimpleMLP()\n",
    "\n",
    "    def make_optimizer(self, parameters) -> torch.optim.Optimizer:\n",
    "        optimizer = torch.optim.SGD(parameters, self.hp.lr, weight_decay=self.hp.weight_decay)\n",
    "        return optimizer\n",
    "\n",
    "    def make_criterion(self):\n",
    "        return softTargetCrossEntropy\n",
    "\n",
    "    def make_scenario(self):\n",
    "        # transform = transforms.Compose(\n",
    "        #     [transforms.ToTensor(), transforms.Normalize((0.2860,), (0.3530,)), transforms.Resize(32)]\n",
    "        # )\n",
    "        scenario: NCScenario = SplitMNIST(\n",
    "            n_experiences=5,\n",
    "            fixed_class_order=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "            dataset_root=DATASETS)\n",
    "\n",
    "\n",
    "        self.outliers = AvalancheDataset(\n",
    "            torchvision.datasets.KMNIST(DATASETS, train=True, download=True, \n",
    "            transform=transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.1918,), (0.3483,))\n",
    "            ]))\n",
    "        )\n",
    "\n",
    "        # self.outliers += AvalancheDataset(\n",
    "        #     torchvision.datasets.MNIST(DATASETS, train=True, download=True, \n",
    "        #     transform=transforms.Compose([\n",
    "        #         transforms.ToTensor(),\n",
    "        #         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        #         transforms.RandomRotation((90, 360-90)),\n",
    "        #     ]))\n",
    "        # )\n",
    "\n",
    "\n",
    "        # Use a uniform distribution for outlier exposure\n",
    "        return scenario\n",
    "\n",
    "    def add_plugins(self):\n",
    "        return [LwFPlugin()]\n",
    "        \n",
    "\n",
    "    def known_known(self, n_classes: int):\n",
    "        def _known_known(y: int) -> Tensor:\n",
    "            new_y = torch.zeros(n_classes)\n",
    "            new_y[y] = 1.0\n",
    "            return new_y\n",
    "        return _known_known\n",
    "\n",
    "    def known_unkown(self, n_classes: int, classes_seen: typing.Set[int]):\n",
    "        def known_unkown(y: int) -> Tensor:\n",
    "            # return y\n",
    "            y = torch.ones(n_classes) * 1/(n_classes-len(classes_seen))\n",
    "\n",
    "            for seen in classes_seen:\n",
    "                y[seen] = 0.0\n",
    "\n",
    "            return y\n",
    "        return known_unkown\n",
    "\n",
    "    def after_train_dataset_adaptation(self, strategy: SupervisedTemplate):\n",
    "        scenario: NCScenario = strategy.experience.benchmark\n",
    "        current_dataset: AvalancheSubset = strategy.adapted_dataset\n",
    "\n",
    "        n_classes: int = scenario.n_classes\n",
    "        self.classes_seen.union(strategy.experience.classes_in_this_experience)\n",
    "        # Build set of outlier exposures\n",
    "        exposure_set = self.outliers.add_transforms(\n",
    "            target_transform=self.known_unkown(n_classes, self.classes_seen))\n",
    "\n",
    "        current_dataset = current_dataset.add_transforms(target_transform=self.known_known(n_classes))\n",
    "\n",
    "        # Random indices ordering \n",
    "        indices = list(range(len(exposure_set)))\n",
    "        shuffle(indices)\n",
    "        indices = indices[:self.hp.exposure_set_size]\n",
    "        exposure_set = AvalancheSubset(exposure_set, indices)\n",
    "        strategy.adapted_dataset = exposure_set + current_dataset\n",
    "\n",
    "    def after_eval_dataset_adaptation(self, strategy):\n",
    "        n_classes =  strategy.experience.benchmark.n_classes\n",
    "        strategy.adapted_dataset = strategy.adapted_dataset.add_transforms(\n",
    "            target_transform=self.known_known(n_classes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Scratch/al183/avalanche/avalanche/training/templates/base.py:200: UserWarning: Plugin <__main__.OE_Experiment object at 0x7fbda8272430> implements incompatible callbacks for template <avalanche.training.templates.supervised.SupervisedTemplate object at 0x7fbd970dccd0>. This may result in errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of experience: 0\n",
      "Current Classes:     [0, 1]\n",
      "Experience size:     12665\n",
      "Start of experience: 1\n",
      "Current Classes:     [2, 3]\n",
      "Experience size:     12089\n",
      "Start of experience: 2\n",
      "Current Classes:     [4, 5]\n",
      "Experience size:     11263\n",
      "Start of experience: 3\n",
      "Current Classes:     [6, 7]\n",
      "Experience size:     12183\n",
      "Start of experience: 4\n",
      "Current Classes:     [8, 9]\n",
      "Experience size:     11800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment = OE_Experiment(\n",
    "    HyperParams(\n",
    "        lr=0.01,\n",
    "        train_mb_size=64,\n",
    "        train_epochs=50,\n",
    "        eval_mb_size=128,\n",
    "        eval_every=-1,\n",
    "        device=\"cuda\",\n",
    "        exposure_set_size=12000,\n",
    "        weight_decay=0.0\n",
    "    )\n",
    ").train()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4839fe716dff7faeda236a63134f028e1f3d97c1113b9276d429fcc26fd67641"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('avalanche-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

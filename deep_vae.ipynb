{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Composition:  [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n",
      "\tLoss_Epoch/train_phase/train_stream/Task000: 2489.61719140625\n",
      "\tclock/0000_epoch: 399\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000: 0.033416666666666664\n",
      "\tTrainLossPart/DeepVAE: 2489.5444128158247\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000: 2270.625125\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000: 0.0375\n",
      "\tEvalLossPart/Experience_0/DeepVAE: 2272.267578125\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001: 2459.556748046875\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001: 0.0725\n",
      "\tEvalLossPart/Experience_1/DeepVAE: 2459.3938903808594\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002: 2388.28405078125\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002: 0.246\n",
      "\tEvalLossPart/Experience_2/DeepVAE: 2388.513427734375\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003: 2419.422357421875\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003: 0.0945\n",
      "\tEvalLossPart/Experience_3/DeepVAE: 2421.24609375\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004: 2704.484935546875\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004: 0.0275\n",
      "\tEvalLossPart/Experience_4/DeepVAE: 2705.7342224121094\n",
      "\tLoss_Stream/eval_phase/test_stream/Task000: 2448.474643359375\n",
      "\tConditional/P(correct|correct_task_id): 0.08641975373029709\n",
      "\tConditional/P(correct|!correct_task_id): 0.11024440824985504\n",
      "\tConditional/P(correct_task_id): 0.6154384613037109\n",
      "\tTaskIdAccuracy: 0.6154999732971191\n",
      "\tTop1_Acc_Stream/eval_phase/test_stream/Task000: 0.0956\n",
      "\tAccuracy_On_Trained_Experiences/eval_phase/test_stream/Task000: 0.0956\n",
      "\tStreamForgetting/eval_phase/test_stream: 0.0012500000000000011\n",
      "\tclock/0001_epoch: 399\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000: 0.0015000000000000013\n",
      "\tclock/0002_epoch: 399\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001: 0.0040000000000000036\n",
      "\tclock/0003_epoch: 399\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002: 0.004500000000000004\n",
      "\tclock/0004_epoch: 399\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp003: -0.0050000000000000044\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from torch.nn.functional import interpolate\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import typing as t\n",
    "import gzip\n",
    "import torch\n",
    "import json\n",
    "from hvae.hvaeoodd.oodd.losses import ELBO\n",
    "import surprisenet.packnet as pn\n",
    "from surprisenet.task_inference import TaskInferenceStrategy\n",
    "from network.deep_vae import FashionMNISTDeepVAE\n",
    "from tqdm import tqdm\n",
    "from config.config import ExpConfig\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        'font.family': 'Alegreya Sans',\n",
    "        'font.size': 12,\n",
    "        \"image.cmap\": \"cividis\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "elbo_loss_func = ELBO()\n",
    "RUN_ROOT=\"/local/scratch/antonlee/log/SurpriseNet/ScheduleSearch/0002_ScheduleSearch\"\n",
    "MODEL_FILENAME = f\"{RUN_ROOT}/model.pt.gz\"\n",
    "CONFIG_FILENAME = f\"{RUN_ROOT}/config.json\"\n",
    "RESULT_FILENAME = f\"{RUN_ROOT}/results.pkl.gz\"\n",
    "CLASS_ORDER_FILENAME = f\"{RUN_ROOT}/class_order.txt\"\n",
    "ROOT=\"/local/scratch/antonlee/datasets/\"\n",
    "\n",
    "cfg = ExpConfig.from_json(CONFIG_FILENAME)\n",
    "cfg.dataset_root = ROOT\n",
    "\n",
    "TASK_COMP = []\n",
    "with open(CLASS_ORDER_FILENAME, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        TASK_COMP.append([int(x) for x in line.split(\",\")])\n",
    "\n",
    "with gzip.open(RESULT_FILENAME, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "CLASS_TO_TASK = {}\n",
    "for task, classes in enumerate(TASK_COMP):\n",
    "    for y in classes:\n",
    "        CLASS_TO_TASK[y] = task\n",
    "\n",
    "print(\"Task Composition: \", TASK_COMP)\n",
    "\n",
    "# Pretty print results\n",
    "final_task = results[-1]\n",
    "for metric, value in final_task.items():\n",
    "    print(f\"\\t{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperienceIdentificationCM\n"
     ]
    }
   ],
   "source": [
    "from network.deep_vae import HVAE\n",
    "from train import Experiment\n",
    "\n",
    "cfg.tensorboard_dir = \"experiment_logs\"\n",
    "exp = Experiment(cfg)\n",
    "model: HVAE = exp.network\n",
    "\n",
    "with gzip.open(MODEL_FILENAME, \"rb\") as f:\n",
    "    state_dict = torch.load(f)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model._subset_count.fill_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Dataset\n",
    "def split_by_class(dataset: Dataset) -> t.List[Dataset]:\n",
    "    \"\"\"Split a dataset into a list of datasets, where each dataset contains only\n",
    "    one class.\n",
    "    \"\"\"\n",
    "    classes = set(map(int, dataset.targets))\n",
    "    datasets = []\n",
    "    for y in classes:\n",
    "        indices = torch.where(dataset.targets == y)[0]\n",
    "        datasets.append(Subset(dataset, indices))\n",
    "    return datasets\n",
    "\n",
    "def random_batch(dataset: Dataset, batch_size: int) -> t.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Return a random batch of `batch_size` from `dataset`\n",
    "    \"\"\"\n",
    "    indices = torch.randperm(len(dataset))[:batch_size]\n",
    "    x = torch.stack([dataset[i][0] for i in indices])\n",
    "    y = torch.tensor([dataset[i][1] for i in indices])\n",
    "    return x, y\n",
    "\n",
    "def display_batch(x: torch.Tensor, scale: float = 4.0, rows: int = 3):\n",
    "    \"\"\"Display a batch of images in a grid\n",
    "    \"\"\"\n",
    "    x = interpolate(x, scale_factor=scale, mode=\"nearest\")\n",
    "    image_grid = make_grid(x, nrow=rows, pad_value=1.0)\n",
    "    return to_pil_image(image_grid)\n",
    "    \n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Resize((32, 32), antialias=True),\n",
    "])\n",
    "\n",
    "joint_dataset = FashionMNIST(ROOT, train=False, transform=transform)\n",
    "test_sets = split_by_class(joint_dataset)\n",
    "display_batch(random_batch(test_sets[0], 9)[0])\n",
    "\n",
    "joint_dataset.taskid = torch.tensor([CLASS_TO_TASK[int(y)] for y in joint_dataset.targets]) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# model.eval()\n",
    "# model.cuda()\n",
    "\n",
    "# active_task = 4\n",
    "# model.use_task_subset(active_task)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dataloader = DataLoader(joint_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "# # mean_stage_0 = []\n",
    "# # means_stage_1 = []\n",
    "# z_stage = []\n",
    "# with torch.no_grad():\n",
    "#     for x, y in tqdm(dataloader):\n",
    "#         x = x.cuda()\n",
    "#         likelihood, stage_data = model.wrapped.forward(x)\n",
    "\n",
    "#         # mean_stage_0.append(stage_data[0].q.mean)\n",
    "#         # means_stage_1.append(stage_data[1].q.mean)\n",
    "#         z_stage.append(stage_data[2].q.z)\n",
    "\n",
    "\n",
    "# # mean_stage_0 = torch.cat(mean_stage_0)\n",
    "# # means_stage_1 = torch.cat(means_stage_1)\n",
    "# z_stage = torch.cat(z_stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # t-sne\n",
    "# tsne = TSNE(n_components=2, random_state=0)\n",
    "# print(\"Fitting t-sne\")\n",
    "# numpy_z = z_stage.flatten(start_dim=1).detach().cpu().numpy()\n",
    "# z_2d = tsne.fit_transform(numpy_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot\n",
    "# plt.figure(figsize=(12, 10))\n",
    "\n",
    "# seen_indices = torch.tensor([], dtype=torch.long)\n",
    "# for composition in TASK_COMP[:active_task+1]:\n",
    "#     for class_label in composition:\n",
    "#         seen_indices = torch.cat([seen_indices, torch.where(joint_dataset.targets == class_label)[0]])\n",
    "\n",
    "# # seen_indices to determine alpha\n",
    "# alpha = torch.ones(len(joint_dataset)) * 0.1\n",
    "# alpha[seen_indices] = 1.0\n",
    "\n",
    "# cmap = plt.get_cmap('tab10', 5)\n",
    "\n",
    "# plt.scatter(\n",
    "#     z_2d[:, 0], z_2d[:, 1], \n",
    "#     c=joint_dataset.taskid.int(),\n",
    "#     alpha=alpha,\n",
    "#     cmap=cmap,\n",
    "#     s=3.0)\n",
    "# # plt.colorbar()\n",
    "# plt.colorbar(cmap=cmap, ticks=range(5), label=\"Task ID\")\n",
    "# plt.title(f\"t-sne Z (k=2) subset {active_task} just saw {TASK_COMP[active_task]}\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.activate_task_id(2)\n",
    "display_batch(model.generate(25), scale=2, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = random_batch(test_sets[3], 9)\n",
    "x = x.cuda()\n",
    "\n",
    "model.activate_task_id(3)\n",
    "\n",
    "likelihood, _ = model.forward(x, use_mode=[True, False, False], decode_from_p=[True, False, False])\n",
    "likelihood_b, _ = model.forward(x, use_mode=[False, False, False], decode_from_p=[False, False, False])\n",
    "\n",
    "# MSE\n",
    "mse = torch.mean((likelihood.samples - x)**2)\n",
    "mse_b = torch.mean((likelihood_b.samples - x)**2)\n",
    "\n",
    "print(\"MSE\", mse)\n",
    "print(\"MSE Abstract\", mse_b)\n",
    "display_batch(likelihood_b.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from surprisenet.task_inference import sample\n",
    "\n",
    "\n",
    "model.cuda().eval()\n",
    "\n",
    "\n",
    "\n",
    "novelty_scores: t.Dict[int, t.List[torch.Tensor]] = {}\n",
    "\n",
    "\n",
    "task_inference = model.task_inference_strategy\n",
    "task_inference.k = 1\n",
    "# forward_func = super(pn.SurpriseNetVariationalAutoEncoder, model).multi_forward\n",
    "\n",
    "for subset in range(5):\n",
    "    novelty_scores[subset] = []\n",
    "\n",
    "    for label, test_set in enumerate(test_sets):\n",
    "        dataloader = DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "\n",
    "        novelty = torch.tensor([], dtype=torch.float32)\n",
    "        model.activate_task_id(subset)\n",
    "        for x, y in tqdm(dataloader):\n",
    "            new_score = task_inference._novelty_score(x.cuda()).cpu()\n",
    "            # new_score, _ = sample(forward_func, x.cuda())\n",
    "            novelty = torch.cat((novelty, new_score.cpu()))\n",
    "    \n",
    "        novelty_scores[subset].append(novelty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subplots\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(10, 2*5), sharex=True, sharey=True)\n",
    "# Remove padding\n",
    "\n",
    "# flattent axes\n",
    "axes = axes.flatten()\n",
    "\n",
    "for subset, class_novelty in novelty_scores.items():\n",
    "    for class_label, novelty in enumerate(class_novelty):\n",
    "        # if class_label != 8:\n",
    "        #     continue\n",
    "        in_task = class_label in TASK_COMP[subset]\n",
    "        \n",
    "        sns.kdeplot(novelty, label=f\"{label} {subset}\", ax=axes[subset], fill=in_task, color=f\"C{class_label}\")\n",
    "\n",
    "        if in_task:\n",
    "            axes[subset].axvline(novelty.mean(), color=f\"C{class_label}\", linestyle=\"-\")\n",
    "        else:\n",
    "            axes[subset].axvline(novelty.mean(), color=f\"C{class_label}\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # for task_id, (c_a, c_b) in enumerate(zip(range(0, 10, 2), range(1, 10, 2))):\n",
    "    #     print(c_a, c_b)\n",
    "    #     novelty = torch.cat((class_novelty[c_a], class_novelty[c_b]))\n",
    "\n",
    "    #     in_task = task_id == subset\n",
    "\n",
    "    #     # if not in_task:\n",
    "    #     #     continue\n",
    "\n",
    "    #     sns.kdeplot(novelty, label=f\"{c_a} {c_b}\", ax=axes[subset], fill=in_task, color=f\"C{c_a}\")\n",
    "\n",
    "    \n",
    "    axes[subset].set_ylabel(f\"Subset {subset+1} Density\")\n",
    "\n",
    "\n",
    "# Change y axis units\n",
    "for ax in axes:\n",
    "    ax.set_xlabel(\"Novelty Score\")\n",
    "\n",
    "# Legend\n",
    "patches = [mpatches.Patch(color=f'C{i}', label='The red data') for i in range(10)]\n",
    "\n",
    "# fashion mnist labels\n",
    "fmnist_label = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\"\n",
    "]\n",
    "\n",
    "\n",
    "axes[0].legend(patches, fmnist_label, loc='upper center', ncol=5, bbox_to_anchor=(0.5, 1.4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on class 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m     16\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m---> 17\u001b[0m     out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mmulti_forward(x)\n\u001b[1;32m     18\u001b[0m     \u001b[39mfor\u001b[39;00m subset_pred \u001b[39min\u001b[39;00m out\u001b[39m.\u001b[39mpred_exp_id:\n\u001b[1;32m     19\u001b[0m         class_task_count[class_label, subset_pred] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/github.com/tachyonicClock/SurpriseNetRun/SurpriseNet/surprisenet/packnet.py:377\u001b[0m, in \u001b[0;36mSurpriseNetDeepVAE.multi_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[39m\"\"\"At eval time we need to try infer the task somehow?\"\"\"\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask_inference_strategy\u001b[39m.\u001b[39;49mforward_with_task_inference(\n\u001b[1;32m    378\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrapped\u001b[39m.\u001b[39;49mmulti_forward, x\n\u001b[1;32m    379\u001b[0m     )\n",
      "File \u001b[0;32m~/github.com/tachyonicClock/SurpriseNetRun/SurpriseNet/surprisenet/task_inference.py:246\u001b[0m, in \u001b[0;36mHierarchicalVAEOOD.forward_with_task_inference\u001b[0;34m(self, forward_func, x)\u001b[0m\n\u001b[1;32m    244\u001b[0m     best_score[swap_mask] \u001b[39m=\u001b[39m new_score[swap_mask]\n\u001b[1;32m    245\u001b[0m     best_out\u001b[39m.\u001b[39mpred_exp_id[swap_mask] \u001b[39m=\u001b[39m i\n\u001b[0;32m--> 246\u001b[0m     _swap_fields(best_out, new_out, swap_mask)\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mactivate_task_id(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39msubset_count())\n\u001b[1;32m    249\u001b[0m best_out\u001b[39m.\u001b[39mnovelty_scores \u001b[39m=\u001b[39m novelty_scores\n",
      "File \u001b[0;32m~/github.com/tachyonicClock/SurpriseNetRun/SurpriseNet/surprisenet/task_inference.py:73\u001b[0m, in \u001b[0;36m_swap_fields\u001b[0;34m(dest, src, swap_mask)\u001b[0m\n\u001b[1;32m     70\u001b[0m         _swap_tensor_elements(dest_value[i], src_value[i], swap_mask)\n\u001b[1;32m     71\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(dest_value, Tensor):\n\u001b[1;32m     72\u001b[0m     \u001b[39m# Swap the whole tensor\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     _swap_tensor_elements(dest_value, src_value, swap_mask)\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(dest_value)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/github.com/tachyonicClock/SurpriseNetRun/SurpriseNet/surprisenet/task_inference.py:54\u001b[0m, in \u001b[0;36m_swap_fields.<locals>._swap_tensor_elements\u001b[0;34m(dest_tensor, src_tensor, swap_mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_swap_tensor_elements\u001b[39m(\n\u001b[1;32m     52\u001b[0m     dest_tensor: Tensor, src_tensor: Tensor, swap_mask: Tensor\n\u001b[1;32m     53\u001b[0m ):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39massert\u001b[39;00m dest_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m src_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m swap_mask\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], (\n\u001b[1;32m     55\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdest_tensor, src_tensor and swap_mask must have the same first dim, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgot \u001b[39m\u001b[39m{\u001b[39;00mdest_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00msrc_tensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00mswap_mask\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     dest_tensor[swap_mask] \u001b[39m=\u001b[39m src_tensor[swap_mask]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.cuda()\n",
    "model.eval()\n",
    "model.task_inference_strategy.n = 5\n",
    "model.task_inference_strategy.k = 1\n",
    "\n",
    "\n",
    "class_task_count = torch.zeros(10, 5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for class_label, test_set in enumerate(test_sets):\n",
    "        dataloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=4)\n",
    "\n",
    "        print(\"Testing on class\", class_label)\n",
    "        for x, y in tqdm(dataloader):\n",
    "            x = x.cuda()\n",
    "            out = model.multi_forward(x)\n",
    "            for subset_pred in out.pred_exp_id:\n",
    "                class_task_count[class_label, subset_pred] += 1\n",
    "\n",
    "task_confusion = torch.zeros(5, 5)\n",
    "\n",
    "for true_task, composition in enumerate(TASK_COMP):\n",
    "    for class_label in composition:\n",
    "        task_confusion[true_task] += class_task_count[class_label]\n",
    "task_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_id_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m\"\u001b[39m\u001b[39mSubset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTask ID Accuracy\u001b[39m\u001b[39m\"\u001b[39m, task_id_accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task_id_accuracy' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, (ax1, ax2) = plt.subplot(1, 2)\n",
    "\n",
    "# plt.imshow(task_confusion)\n",
    "\n",
    "# # What percentage lies on the diagonal?\n",
    "# task_id_accuracy = task_confusion.diag().sum() / task_confusion.sum()\n",
    "\n",
    "plt.imshow(class_task_count, aspect=0.5)\n",
    "plt.xlabel(\"Subset\")\n",
    "plt.ylabel(\"Class\")\n",
    "print(\"Task ID Accuracy\", task_id_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
